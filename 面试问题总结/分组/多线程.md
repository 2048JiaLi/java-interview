[TOC]

# 一、线程池

## 1.1、线程池介绍

线程就是我们**程序执行的实体**。在服务器开发领域，我们经常会为每个请求分配一个线程去处理，但是**线程的创建销毁、调度都会带来额外的开销**，线程太多也会导致系统整体性能下降。在这种场景下，我们通常会提前创建若干个线程，通过线程池来进行管理。当请求到来时，只需从线程池选一个线程去执行处理任务即可。

线程池常常和**队列**一起使用来实现**任务调度**，主线程收到请求后将创建对应的任务，然后放到队列里，线程池中的工作线程等待队列里的任务。

> 为什么要使用线程池，线程池有什么用？
>
> 1. 降低资源消耗：通过重用已经创建的线程来降低线程创建和销毁的消耗
> 2. 提高响应速度：任务到达时不需要等待线程创建就可以立即执行
> 3. 提高线程的可管理性：线程池可以统一管理、分配、调优和监控

## 1.2、新任务提交线程池的工作步骤

1、线程池判断核心线程池里的线程是否都在执行任务。若不是，则创建一个新的工作线程来执行任务；若是，则执行下一步

2、线程池判断工作队列是否满。若没满，则将提交的新任务存储在工作队列进行等待。若满，则执行下一步

3、判断线程池的线程是否都处在工作状态。若没有，则创建一个新的工作线程来执行任务；若都在工作，则交给饱和策略处理该任务。

## 1.3、常见的线程池

### a、newFixedThreadPool (固定数目线程的线程池)

> 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 

```java
public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue<Runnable>());
}
```

**该线程池的工作机制是：**

- 线程数少于核心线程数，也就是设置的线程数时，新建线程执行任务

- 线程数等于核心线程数后，将任务加入阻塞队列（`LinkedBlockingQueue`）
  - 由于队列容量非常大(`Integer.MAX_VALUE`)，可以一直加加加。(当线程池中的任务比较特殊时，比如关于数据库的长时间的IO操作，可能导致OOM)

- 执行完任务的线程反复去队列中取任务执行

**适用场景：**

`FixedThreadPool` 适用于处理CPU密集型的任务，确保CPU在长期被工作线程使用的情况下，尽可能的少的分配线程即可。

### b、newSingleThreadExecutor(单线程的线程池)

> 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

```java
public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue<Runnable>()));
}
```

**工作机制是：**

1. 线程池中没有线程时，新建一个线程执行任务
2. 有一个线程以后，将任务加入阻塞队列`LinkedBlockingQueue`，不停加加加
3. 唯一的这一个线程不停地去队列里取任务执行

**适用场景：**

`SingleThreadExecutor`适用于串行执行任务的场景，每个任务必须按顺序执行，不需要并发执行。

### c、newCachedThreadPool(可缓存线程的线程池)

> 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。

```cpp
public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue<Runnable>());
}
```

**该线程池的工作机制是：**

1. 没有核心线程，直接向阻塞队列`SynchronousQueue`中提交任务

   > SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于`LinkedBlockingQueue`

2. 如果有空闲线程，就去取出任务执行；如果没有空闲线程，就新建一个

3. 执行完任务的线程有60秒生存时间，如果在这个时间内可以接到新任务，就可以继续活下去，否则就拜拜

   > 由于空闲 60 秒的线程会被终止，长时间保持空闲的 CachedThreadPool 不会占用任何资源。

**适用场景：**

`CachedThreadPool` 用于并发执行大量短期的小任务。

### d、newScheduledThreadPool(定时及周期执行的线程池)

> 创建一个定长线程池，支持定时及周期性任务执行。

```java
public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
    return new ScheduledThreadPoolExecutor(corePoolSize);
}


public ScheduledThreadPoolExecutor(int corePoolSize) {
    super(corePoolSize, Integer.MAX_VALUE,
          DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS,
          new DelayedWorkQueue());
}

private static final long DEFAULT_KEEPALIVE_MILLIS = 10L;
```

**线程池特点：**

- 最大线程数为`Integer.MAX_VALUE`
- 阻塞队列是`DelayedWorkQueue`

> DelayQueue：中封装了一个优先级队列，这个队列会对队列中的`ScheduledFutureTask`对象 进行排序，两个任务的执行 time 不同时，time 小的先执行；否则比较添加到队列中的`ScheduledFutureTask`的顺序号 `sequenceNumber` ，先提交的先执行。

**适用场景：**

`ScheduledThreadPoolExecutor`用于需要多个后台线程执行周期任务，同时需要限制线程数量的场景。

## 1.3、线程池的组成部分

1、线程池管理器（ThreadPoolManager）:用于创建并管理线程池
2、工作线程（WorkThread）: 线程池中线程
3、任务接口（Task）:每个任务必须实现的接口，以供工作线程调度任务的执行。
4、任务队列:用于存放没有处理的任务。提供一种缓冲机制。

## 1.4、线程池状态

线程池有这几个状态

```java
   //线程池状态
   private static final int RUNNING    = -1 << COUNT_BITS;
   private static final int SHUTDOWN   =  0 << COUNT_BITS;
   private static final int STOP       =  1 << COUNT_BITS;
   private static final int TIDYING    =  2 << COUNT_BITS;
   private static final int TERMINATED =  3 << COUNT_BITS;
```

- **RUNNING**
  - 该状态的线程池会接收新任务，并处理阻塞队列中的任务;
  - 调用线程池的shutdown()方法，可以切换到SHUTDOWN状态;
  - 调用线程池的shutdownNow()方法，可以切换到STOP状态;

- **SHUTDOWN**
  - 该状态的线程池不会接收新任务，但会处理阻塞队列中的任务；
  - 队列为空，并且线程池中执行的任务也为空,进入TIDYING状态;
- **STOP**
  - 该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务；
  - 线程池中执行的任务为空,进入TIDYING状态;
- **TIDYING**
  - 该状态表明所有的任务已经运行终止，记录的任务数量为0。
  - terminated()执行完毕，进入TERMINATED状态
- **TERMINATED**
  - 该状态表示线程池彻底终止

## 1.5、线程池有哪几种工作队列

- ArrayBlockingQueue （有界队列）：是一个**基于数组结构的有界阻塞队列**，此队列按 FIFO（先进先出）原则对元素进行排序。

- LinkedBlockingQueue （无界队列）：一个**基于链表结构的阻塞队列**，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法`Executors.newFixedThreadPool()`使用了这个队列。

- SynchronousQueue（同步队列）: 一个**不存储元素的阻塞队列**。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。

- DelayQueue（延迟队列）：一个**任务定时周期的延迟执行的队列**。根据指定的**执行时间从小到大排序**，否则根据插入到队列的先后排序。

- PriorityBlockingQueue（优先级队列）: 一个具有**优先级得无限阻塞队列**。

## 1.6、无界队列和有界队列

- 有界队列即长度有限，满了以后ArrayBlockingQueue会插入阻塞。
- 无界队列就是里面能放无数的东西而不会因为队列长度限制被阻塞，但是可能会出现OOM异常。

## 1.7、线程池重要的参数

- `corePoolSize`：核心池的大小，在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中
- `maximumPoolSize`：线程池最大线程数最大线程数
- `keepAliveTime`：表示线程没有任务执行时最多保持多久时间会终止
- `unit`：参数keepAliveTime的时间单位TimeUtil类的枚举类（DAYS、HOURS、MINUTES、SECONDS 等）
- `workQueue`：阻塞队列，用来存储等待执行的任务
- `threadFactory`：线程工厂，主要用来创建线程
- `handler`：拒绝处理任务的策略
  - `AbortPolicy`：丢弃任务并抛出 RejectedExecutionException 异常。（默认这种）
  - `DiscardPolicy`：也是丢弃任务，但是不抛出异常
  - `DiscardOldestPolicy`：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
  - `CallerRunsPolicy`：由调用线程处理该任务

## 1.8、 **线程池中 submit()和 execute()方法有什么区别？**

- 接收的参数不一样
- submit有返回值，而execute没有
- submit方便Exception处理

# 二、进程与线程

## 2.1、进程和线程的区别

- **根本区别**：进程是操作系统**资源分配**的基本单位，而线程是处理器**任务调度和执行**的基本单位

  > 每个进程都有自己独立的一块内存空间，一个进程可以有多个线程

- **资源开销**：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。

- **包含关系**：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。

- **内存分配**：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的

- **影响关系**：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。

- **执行过程**：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

## 2.2、线程的生命周期

**新建( new )：**新创建了一个线程对象；

**可运行( runnable )：**线程对象创建后，其他线程(比如 main 线程）调用了该对象的 start ()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获 取CPU的使用权；

**运行( running )：**可运行状态( runnable )的线程获得了CPU时间片（ timeslice ） ，执行程序代码；

**阻塞( block )：**阻塞状态是指线程因为某种原因放弃了CPU 使用权，也即让出了 CPU timeslice ，暂时停止运行。直到线程进入可运行( runnable )状态，才有 机会再次获得 cpu timeslice 转到运行( running )状态。

阻塞的情况分三种：

1. 等待阻塞：运行( running )的线程执行 o . wait ()方法， JVM 会把该线程放 入等待队列( waitting queue )中。
2. 同步阻塞：运行( running )的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则 JVM 会把该线程放入锁池( lock pool )中。
3. 其他阻塞: 运行( running )的线程执行 Thread . sleep ( long ms )或 t . join ()方法，或者发出了 I / O 请求时， JVM 会把该线程置为阻塞状态。当 sleep ()状态超时、 join ()等待线程终止或者超时、或者 I / O 处理完毕时，线程重新转入可运行( runnable )状态。

**死亡( dead )：**线程 run ()、 main () 方法执行结束，或者因异常退出了 run ()方法，则该线程结束生命周期。死亡的线程不可再次复生。

## 2.3、进程之间的通信方式

进程间通信（IPC，InterProcess Communication）是指在不同进程之间传播或交换信息。

- 进程用户空间是相互独立的，一般而言是不能相互访问的。但很多情况下进程间需要互相通信，来完成系统的某项功能。进程通过与内核及其它进程之间的互相通信来协调它们的行为。

IPC的方式通常有**管道（包括无名管道和命名管道）、消息队列、信号量、共享内存、Socket、信号 **。

### a、管道( pipe )

> 速度慢，容量有限，只有父子进程能通讯  

管道包括三种:

- 普通管道PIPE： 通常有两种限制,一是单工,只能单向传输;二是只能在父子或者兄弟进程间使用.
- 流管道s_pipe: 去除了第一种限制,为半双工，只能在父子或兄弟进程间使用，可以双向传输.
- 命名管道:name_pipe：去除了第二种限制,可以在许多并不相关的进程之间进行通讯.

### b、信号量( semophore ) 

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

### c、消息队列( message queue ) 

消息队列，就是一个消息的链表，是一系列保存在内核中消息的列表。用户进程可以向消息队列添加消息，也可以向消息队列读取消息。

消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。

可以把消息看做一个记录，具有特定的格式以及特定的优先级。对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息，对消息队列有读权限的进程可以从消息队列中读取消息。

**进程间通过消息队列通信，主要是：创建或打开消息队列，添加消息，读取消息和控制消息队列。**

### d、信号 ( sinal ) 

- 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

### e、共享内存( shared memory ) 

- 共享内存允许**两个或多个进程共享一个给定的存储区**，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，**一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取错做读出**，从而实现了进程间的通信。

  >  采用共享内存进行通信的一个主要好处是**效率高**，因为进程可以直接读写内存，而不需要任何数据的拷贝，对于像管道和消息队里等通信方式，则需要再内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次：一次从输入文件到共享内存区，另一次从共享内存到输出文件。

  共享内存有两种实现方式：1、内存映射 2、共享内存机制

### f、套接字( socket ) ：

- 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。

## 2.4、进程通信的应用场景

- **数据传输**：一个进程需要将它的数据发送给另一个进程，发送的数据量在一个字节到几兆字节之间。
- **共享数据**：多个进程想要操作共享数据，一个进程对共享数据的修改，别的进程应该立刻看到。
- **通知事件**：一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。
- **资源共享**：多个进程之间共享同样的资源。为了作到这一点，需要内核提供锁和同步机制。
- **进程控制**：有些进程希望完全控制另一个进程的执行（如Debug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。

## 2.5、什么情况下使用进程和线程

1、需要频繁创建销毁的优先使用线程；因为对进程来说创建和销毁一个进程代价是很大的
2、线程的切换速度快，所以在需要大量计算，切换频繁时用线程，还有耗时的操作使用线程可提高应用程序的响应
3、因为对CPU系统的效率使用上线程更占优，所以可能要发展到多机分布的用进程，多核分布用线程
4、并行操作时使用线程，如C/S架构的服务器端并发线程响应用户的请求
5、需要更稳定安全时，适合选择进程；需要速度时，选择线程更好

> 进程之间相互独立，安全性高，但是开销大
>
> 线程非常高效，但是一个线程死掉，就等于整个进程死掉

# 三、锁

## 3.1、死锁

### a、四个必要条件

- 互斥条件：在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则**请求进程只能等待**。

- 不可剥夺：进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放（只能是**主动释放**)。

- 请求和保持：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。

  > 请求其他资源得不到满足时，并不会释放已有资源

- 循环等待：存在一种进程资源的循环等待链

**以上这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁**

### b、产生

- 一个资源每次只能被一个进程使用
- 一个进程因请求发生阻塞时，依然对已获得的资源保持不放
- 进程已经获得资源使用权，但是一直未使用
- 同一个进程，频繁的获取资源的优先使用权，一直未释放

### c、防止

- 加锁顺序（线程按照一定的顺序加锁）
- 加锁时限（线程尝试获取锁的时候加上一定的时限，超过时限则放弃对该锁的请求，并释放自己占有的锁）
- 死锁检测（一般是将所有的锁存放于`map`对象中，检测`map`中的锁）

## 3.2、乐观锁和悲观锁

### a、定义

1、乐观锁：顾名思义，**对每次的数据操作都保持乐观的态度**，不担心数据会被修改，所以不会对数据进行上锁。由于数据没有上锁，这就存在数据会被多人读写的情况。所以每次修改数据的时候需要对数据进行判断是否被修改过。

2、悲观锁：与乐观锁相反，**对每次的数据操作都保存悲观的态度**，总是担心数据会被修改，所以在自己操作的时候会对数据上锁，防止在自己操作的时候被他人同时操作导致更新丢失。

### b、**使用场景**

1、乐观锁：由于乐观锁的不上锁特性，所以在性能方面要比悲观锁好，比较适合用在DB的读大于写的业务场景。

2、悲观锁：对于每一次数据修改都要上锁，如果在DB读取需要比较大的情况下有线程在执行数据修改操作会导致读操作全部被挂载起来，等修改线程释放了锁才能读到数据，体验极差。所以比较适合用在DB写大于读的情况。

### c、乐观锁一定就是好吗？

乐观锁避免了悲观锁独占对象的现象，同时也提高了并发性能，但它也有缺点：

1. 乐观锁只能保证一个共享变量的原子操作。如果多一个或者几个变量，乐观锁将变得力不从心。但互斥锁能轻易解决。
2. 长时间自旋可能导致开销大。假如CAS长时间不成功而一直自旋，会给CPU带来很大的开销。
3. ABA问题。CAS的核心思想是通过比对内存值与预期值是否一样而判断内存值是否被改过，但这个判断逻辑不严谨。假设内存之原来是A，后来被某线程改为B，最后又被改为A，但CAS认为此内存值并没有发生改变。这种情况对依赖过程值的情景的运算影响很大。

## 3.3、什么是自旋锁

当线程A想要获取一把自旋锁而该锁又被其它线程锁持有时，线程A会在一个循环中自旋以检测锁是不是已经可用了。 

自旋锁需要注意：

- 由于自旋时不释放CPU，因而持有自旋锁的线程应该尽快释放自旋锁，否则等待该自旋锁的线程会一直自旋，造成很大资源浪费
- 持有自旋锁的线程在sleep之前应该释放自旋锁以便其他线程可以获得自旋锁

目前JVM实现自旋锁会消耗CPU，自旋锁比较适用于锁使用者保持锁时间比较短的情况，此时效率较高。

自旋锁是一种对多处理器相当有效的机制，而在单处理器非抢占式系统中基本没有作用。

## 3.4、可重入锁

- **可重入锁又名递归锁**，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），**不会因为之前已经获取过还没释放而阻塞**。

  > Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。

**实现原理**

- 对于锁，底层以`volatile int state`标识，并且初始为0（无抢占）
- 当某线程获得该锁时，会将`state`加1
- 通过线程id，当该线程再次请求该锁（递归内部）时，仅会将`state`再加1，释放时减1
- 而其他线程，只有`state=0`时，才能获得锁



# 四、lock和synchronize的区别

| 类别     | synchronized                                                 | lock                                                         |
| :------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存在层次 | java的关键字，在jvm层面上                                    | 是一个类                                                     |
| 锁的释放 | 1、以获取锁的线程执行完同步代码，释放锁2、线程执行发生异常，jvm会让线程释放锁 | 在finally中必须释放锁，不然容易造成线程死锁                  |
| 锁的获取 | 假设A线程获得锁，B线程等待，如果A线程阻塞，B线程会一直等待   | 分情况而定，lock有多个锁获取的方法，可以尝试获得锁，线程可以不用功一直等待 |
| 锁状态   | 无法判断                                                     | 可以判断                                                     |
| 锁类型   | 可以重入，不可以中断，非公平                                 | 可重入 可以判断 可公平                                       |
| 性能     | 少量同步                                                     | 大量同步                                                     |

## 4.1、与Synchronized相比，可重入锁ReentrantLock实现原理有什么不同？

锁的实现原理基本目的是：让所有线程都能看到某种标记。

- `Synchronized`通过在对象头中设置标记实现该目的，是一种JVM原生锁的实现方式
- `ReentrantLock`以及所有的基于`Lock`接口的实现类，都是通过用一个`volitile`修饰的`int`型变量，并保证每个线程都能拥有对该int的可见性和原子修改。

### a、ReentrantLock与synchronized区别

（1）synchronized是独占锁，加锁和解锁的过程自动进行，易于操作，但不够灵活。ReentrantLock也是独占锁，加锁和解锁的过程需要手动进行，不易操作，但非常灵活。

（2）synchronized可重入，因为加锁和解锁自动进行，不必担心最后是否释放锁；ReentrantLock也可重入，但加锁和解锁需要手动进行，且次数需一样，否则其他线程无法获得锁。

（3）synchronized不可响应中断，一个线程获取不到锁就一直等着；ReentrantLock可以响应中断。



> ReentrantLock还可以实现公平锁机制。什么叫公平锁呢？也就是**在锁上等待时间最长的线程将获得锁的使用权**。通俗的理解就是谁排队时间最长谁先执行获取锁。

## 4.2、**synchronized 底层实现原理？**

synchronized可以保证方法或者代码块在运行时，同一时刻只有一个方法可以进入到临界区，同时它还可以保证共享变量的内存可见性。

Java中每一个对象都可以作为锁，这是synchronized实现同步的基础：

- 普通同步方法，锁是当前实例对象
- 静态同步方法，锁是当前类的class对象
- 同步方法块，锁是括号里面的对象

## 4.3、Syn**synchronized 底层实现原理？**chronized在内存层面如何实现加锁和释放锁

- 进入Synchronized代码块时，会将代码块内用到的变量从该线程的工作内存中清除，转而从内存中获取
- 退出时，将代码块内用到的变量修改，刷新到内存中

## 4.4、使用Synchronized注意事项

- 锁对象不能为空
- 作用域不宜过大（同步代码块优于同步方法）
- 避免死锁





# 五、线程安全 / 不安全

## 5.1、什么是线程安全 / 不安全

### a、线程安全

当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替进行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么称这个类是线程安全的。

### b、线程不安全

不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据。

**线程安全问题都是由全局变量及静态变量引起的。**若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。

## 5.2、线程同步的几种方式

### a、Synchronized关键字

- 修饰方法`public synchronized …`，内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。

  > 注： synchronized关键字也可以修饰静态方法，此时如果调用该静态方法，将会**锁住整个类**

- 同步代码块`synchronized(对象){}`，通常没有必要同步整个方法，使用synchronized代码块同步关键代码即可。

  > 1.当synchronized作用在方法上的时候，锁住的就是这个对象的实例 synchronized(this). 
  >
  > 2.当一个线程访问synchronized(this) 同步块时， 另一个线程仍然可以访问当前对象内的非synchroinzed(this)同步块代码
  >
  > 3.同步是一个耗性能的操作，因此我们尽量减少同步的内容，最好不要加载整个方法上

### b、wait()与notify()

- wait()使一个线程处于等待状态，并且释放所持有的对象的lock；
- notify()唤醒线程

### c、volatile关键字

volatile关键字为域变量的访问提供了一种免锁机制

只需在account前面加上volatile修饰，即可实现线程同步

```java
class Bank e{
            //需要同步的变量加上volatile
            private volatile int account = 100;

            public int getAccount() {
                return account;
            }
            //这里不再需要synchronized 
            public void save(int money) {
                account += money;
            }
        ｝
```

1. 多线程中的非同步问题主要出现在对域的读写上，如果让域自身避免这个问题，则就不需要修改操作该域的方法。

2. volatile不能保证原子操作，因此**volatile不能代替synchronized**

3. 每次要线程要访问volatile修饰的变量时都是从内存中读取，而不是从缓存当中读取，因此每个线程访问到的变量值都是一样的。这样就保证了同步。

### d、java.util.concurrent包

## 5.3、sleep() 和wait() 有什么区别? 

- sleep 是线程类（Thread）的方法，导致此线程暂停执行指定时间，给执行机会给其他线程，但是监控状态依然保持，到时后会自动恢复。调用sleep 不会释放对象锁。
- wait 是Object 类的方法，对此对象调用wait 方法导致本线程放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象发出notify 方法（或notifyAll）后本线程才进入对象锁定池准备获得对象锁进入就绪状态。

## 5.4、**notify()和 notifyAll()有什么区别？**

如果线程调用了对象的 wait()方法，那么线程便会处于该对象的等待池中，等待池中的线程不会去竞争该对象的锁。

- 当有线程调用了对象的 **notifyAll()方法（唤醒所有 wait 线程）**或 **notify()方法（只随机唤醒一个 wait 线程）**，被唤醒的的线程便会进入该对象的锁池中，锁池中的线程会去竞争该对象锁。

  > 调用了notify后只有一个线程会由等待池进入锁池，而notifyAll会将该对象等待池内的所有线程移动到锁池中，等待锁竞争。

- 优先级高的线程竞争到对象锁的概率大，假若某线程没有竞争到该对象锁，它还会留在锁池中，唯有线程再次调用 wait()方法，它才会重新回到等待池中。而竞争到对象锁的线程则继续往下执行，直到执行完了 synchronized 代码块，它会释放掉该对象锁，这时锁池中的线程会继续竞争该对象锁。

## 5.5、**线程的 run()和 start()有什么区别？**

每个线程都是通过某个特定Thread对象所对应的方法run()来完成其操作的，方法run()称为线程体。**通过调用Thread类的start()方法来启动一个线程。**

**start()方法来启动一个线程**，真正实现了多线程运行。这时**无需等待run方法体代码执行完毕**，可以直接继续执行下面的代码； 这时此线程是处于就绪状态， 并没有运行。 然后通过此Thread类调用方法run()来完成其运行状态， 这里方法run()称为线程体，它包含了要执行的这个线程的内容， Run方法运行结束， 此线程终止。然后CPU再调度其它线程。

**run()方法是在本线程里的，只是线程里的一个函数,而不是多线程的**。 如果直接调用run(),其实就相当于是调用了一个普通函数而已，直接待用run()方法必须等待run()方法执行完毕才能执行下面的代码，所以执行路径还是只有一条，根本就没有线程的特征，所以在多线程执行时要使用start()方法而不是run()方法。



# 六、java创建多线程的方式

## 6.1、方式

> 创建线程的方式，也可以说只有一种，就是Thread。
>
> 因为，无论Callable，Runnable，ThreadPool，最终都是使用Thread.start()开启线程

- 继承`Thread`，重写`run`方法，其本身就是实现了 `Runnable` 接口
- 实现 `Runnable` 接口，并重写`run`方法
- 实现java.util.concurrent下的`Callable`接口，并重写`call`方法
- 线程池

## 6.2、Runnable和Callable的区别

### a、相同点

1、两者都是接口；（废话）
2、两者都可用来编写多线程程序；
3、两者都需要调用Thread.start()启动线程；

### b、不同点

1、两者最大的不同点是：实现Callable接口的任务线程能返回执行结果；而实现Runnable接口的任务线程不能返回结果；
2、Callable接口的call()方法允许抛出异常；而Runnable接口的run()方法的异常只能在内部消化，不能继续上抛；

## 6.3、启动一个线程是用run()还是start()?

启动一个线程是调用start()方法，使线程所代表的虚拟处理机处于可运行状态，这意味着它可以由JVM 调度并执行。这并不意味着线程就会立即运行。run()方法可以产生必须退出的标志来停止一个线程。

## 6.4、三个线程顺序执行的实现方式

就是三个线程，假设是线程 1，2，3， 现在的要求是：必须是线程 1 先执行，然后线程 2 再执行，最后是线程 3 执行

然后有几种实现方法呢？

其实它的本质就是实现，让线程 2，3 等待线程 1 执行完毕，所以重点就是有哪些方法可以让线程 2，3 等待

### a、join

在线程 B 中调用了线程 A 的 join 方法，那么线程 B 就会等线程 A 执行结束之后再执行

### b、设置信号量，CountDownLatch

信号量跟线程相对应的时候，该线程才执行

### c、使用单个线程池

之所以线程 1，2，3 的执行顺序无法保证，是因为在编译器可能会去做一些优化，导致没有办法按照顺序执行

如果使用单个线程池去执行的话，那就没有这样的问题了